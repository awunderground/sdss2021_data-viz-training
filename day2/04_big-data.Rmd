---
title: "Day 2: Big Data"
author: "Aaron R. Williams"
output:
  html_document:
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    css: !expr here::here("www", "web_report.css")
    editor_options:
      chunk_output_type: console
---

<style>
@import url('https://fonts.googleapis.com/css?family=Lato&display=swap');
</style>

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" />

```{css echo=FALSE}
h1 {
    font-size: 34px;
    color: #337AB7;
}
p {
    margin: 20px 0 20px;
}
```

```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

```{r}
library(tidyverse)

```

## Big Data

Our examples thus far have focused on data sets with a modest number of observations and variables. Larger data sets can create new challenges. 

## Challenge 1: Overplotting

*Glyphs* are representations of data in data visualizations. *Overplotting* is when some glyphs in a data visualization obscure other glyphs. Overplotting is common when there is a highly frequent observation, if there is a lack of precision, or too many observations. 

## Challenge 2: Too many pairwise comparisons

If $m$ is the number of variable in a data set, then there are $\frac{m(m - 1)}{2}$ pairwise relationships in a data set. 

```{r}
tibble(m = 2:200) %>%
  mutate(`Pairwise Relationships` = m * (m - 1) / 2) %>%
  ggplot(aes(m, `Pairwise Relationships`)) +
  geom_line() + 
  labs(title = "The Number of Pairwise Relationships Explodes in Modestly Wide Data") +
  scale_y_continuous(labels = scales::comma) +
  theme_minimal()

```

## Overplotting

### `r kableExtra::text_spec("Exercise 1", color = "#1696d2")`

A data set doesn't need thousands of observations to have overplotting. Consider a simple example using the `mpg` data set from `library(ggplot2)`. 

<font color="#55b748">Step 1:</font> Create this plot using the `mpg` data set with variables `cyl` and `hwy`. 

```{r echo = FALSE}
mpg %>%
  ggplot() +
  geom_point(aes(cyl, hwy)) +
  theme_minimal()

```

<font color="#55b748">Step 2:</font> Use `nrow(mpg)` to count the number of observations in `mpg`. Is there overplotting?

<font color="#55b748">Step 3:</font> Replace `geom_point()` with `geom_jitter()`. What happens?

<font color="#55b748">Step 4:</font> Experiment with the `width` and `height` arguments. You can see the documentation with `?geom_jitter`. What seems to be the best "best" combination?

The first pillar in The Seven Pillars of Statistical Wisdon by Stephen Stigler identifies an interesting paradox: 

>"By aggregating, you lose the identity of the individual, so you’re throwing away information, but you’re also gaining information of a different sort. No one wants to be reduced to a statistic, but by losing the identity of the individual, you are producing information about the group."

`geom_jitter()` creates a similar paradox. Just like how we gain information by throwing out information with aggregation, we can gain clarity by introducing errors to our data with `geom_jitter()`. 

### `r kableExtra::text_spec("Exercise 2", color = "#1696d2")`

Now we'll focus on the `diamonds` data set from `library(ggplot2)`. It contains information about 53,940 diamonds.

```{r}
glimpse(diamonds)

```

<font color="#55b748">Step 1:</font> Create a scatter plot with the diamonds data set that shows the relationship between `carat` and `price`. 

<font color="#55b748">Step 2:</font> Is there is overplotting?

<font color="#55b748">Step 3:</font> Try the following changes:

* Change the size of points with the `size` argument in `geom_point()`.
* Change to hollow points with `shape = 1` in `geom_point()`.
* Add transparency to points with `alpha = 0.1` in `geom_point()`.
* Use `facet_wrap()` and `facet_grid()`
* Try sampling with the following:

```
diamonds %>% 
  slice_sample(n = 1000) %>%
  ggplot() + ...

```

<font color="#55b748">Step 4:</font> Which do you prefer? What did you learn about the data with this different techniques?

### `r kableExtra::text_spec("Exercise 3", color = "#1696d2")`

We'll continue with the `diamonds` data set. This time we'll experiment with some summaries instead of visualizing all glyphs directly. 

<font color="#55b748">Step 1:</font> Create a scatter plot with the diamonds data set that shows the relationship between `carat` and `price`. 

<font color="#55b748">Step 2:</font> Try the following changes:

* Use `geom_hex()` instead of `geom_point()` for multi-dimensional binning with hexagons. Experiment with different values for the argument `bins`.
* Add `geom_smooth()` to add a model on top of the points. 

## Wide Data

Techniques for visualizing wide data, and dimension reduction more broadly, are far less settled in the literature. 

### `r kableExtra::text_spec("Exercise 4", color = "#1696d2")`

parallel coordinate plots (Inselberg 1985)

<font color="#55b748">Step 1:</font> Install and load the `GGally` package. 

<font color="#55b748">Step 2:</font> Use the following code to get a subset of observations from the diamonds data set. 

```
diamonds %>%
  select(where(is.numeric), species) %>%
  slice_sample(n = 50)

```

<font color="#55b748">Step 3:</font> Pipe (`%>%`) the data into `ggparcoord(columns = 1:4)`.

<font color="#55b748">Step 4:</font> Add `alphaLines = 0.3` inside of `ggparcoord()`.

<font color="#55b748">Step 5:</font> Add `groupColumn = 6` inside of `ggparcoord()`.

### `r kableExtra::text_spec("Exercise 5", color = "#1696d2")`

scatterplot matrices (Carr 1985)

<font color="#55b748">Step 1:</font> Install and load the `GGally` package. 

<font color="#55b748">Step 2:</font> Use `select(cty, hwy, year, fl, displ)` to pick a subset of variables from the `mpg` data set. **Warning:** This function will crash R if too many variables are included. 

<font color="#55b748">Step 3:</font> Run `ggpairs()` on the subset of variables from `mpg`.

### `r kableExtra::text_spec("Exercise 6", color = "#1696d2")`

Here we have a data set with 493 votes from two years of the 114th Senate (2015-2017). The data set has 100 rows and 495 observations. An affirmative vote is `1`, a negative vote is `-1`, and an abstention is `0`. The data are from [Bradley Robinson](https://data.world/bradrobinson/us-senate-voting-records) and this example is based on an earlier analysis by Professor Sivan Leviyang. 

<font color="#55b748">Step 1:</font> Load the votes data with

```
votes <- read_csv("votes.csv")

```

<font color="#55b748">Step 2:</font> Run PCA with the following code

```{r eval = FALSE}
# select the numeric variables
votes_numeric <- votes %>%
  select_if(is.numeric)

# run PCA
votes_pca <- prcomp(votes_numeric)

# extract the principle components
votes_pcs <- votes_pca %>%
  .$x %>%
  as_tibble()

# combine the pcs to the names and parties
votes_pcs <- bind_cols(
  select(votes, name, party),
  votes_pcs
)

summary(votes_pca)

```

<font color="#55b748">Step 3:</font> Use `x = PC1`, `y = PC2`, and `geom_point()` to plot the data. 

<font color="#55b748">Step 4:</font> Add `party` as color. Try labeling a few individual observations. 

<font color="#55b748">Step 5:</font> Add `x` and `y` labels that include the proportion of variation explained by each PC. 

```{r include = FALSE, eval = FALSE}
# plot the data
names <- c("Bernie Sanders", "Ted Cruz", "Joe Manchin", "Susan Collins")

ggplot() +
  geom_point(data = votes_pcs, aes(PC1, PC2, color = party),
             alpha = 0.5) +
  geom_text(data = filter(votes_pcs, name %in% names), aes(PC1, PC2, label = name)) +
  scale_color_manual(values = c("blue", "#228B22", "red")) +
  labs(title = "PC1 and PC2 of 114th Senate Votes",
       x = "PC1 (0.63 of Variation)",
       y = "PC2 (0.05 of Variation)") +
  theme_minimal() +
  guides(text = NULL)

```

Other techniques include but are not limited to:

* t-Distributed Stochastic Neighbor Embedding (t-SNE) (Maaten and Hinton, 2008)
* Uniform Manifold Approximation and Projection (UMAP) (Mciness et al., 2018)
* Grand tours (Asimov, 1985)
* Rotating plots (Cook and Miller, 2006)
